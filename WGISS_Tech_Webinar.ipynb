{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Web Service of Time Series of Earth Observation Data\n",
    "\n",
    "## Context: The e-sensing project\n",
    "\n",
    "The e-sensing project is about developing new ways to extract information on land use and land cover change from big Earth Observation data sets. We address the following scientific question: \n",
    "\n",
    "***How can we use e-science methods and techniques to improve the extraction of land use and land cover change information from big Earth Observation data sets in an open and reproducible way?*** \n",
    "\n",
    "To answer this, our project is building a new generation of knowledge platform for handling big geospatial data. We're conceiving, building, and deploying a new type of knowledge platform for accessing, processing and analyzing big Earth Observation data.\n",
    "\n",
    "We assume that decades of satellite images can be effectively organized into a data structure which can be efficiently queried and processed using the array data model. \n",
    "\n",
    "<img src=\"img/datacube.png\" alt=\"A data cube of satellite images is as an array\" title=\"data cube\" height=\"300\" width=\"400\" />\n",
    "\n",
    "Our approach is to put data and analysis together to help scientists to do larger, longer, and faster research on land use and land cover change.\n",
    "\n",
    "<img src=\"img/architecture.png\" alt=\"e-sensing project's architecture \" title=\"e-sensing architecture\" height=\"300\" width=\"400\" />\n",
    "\n",
    "The \"e-sensing\" project is supported by __[FAPESP](http://bv.fapesp.br/pt/auxilios/89598/e-sensing-analise-de-grandes-volumes-de-dados-de-observacao-da-terra-para-informacao-de-mudancas-de/)__, under the  __[e-science program](http://www.fapesp.br/8436)__ .\n",
    "\n",
    "For additional information, please visits us at:\n",
    "\n",
    "- our  __[official page](http://esensing.org/)__ \n",
    "- our code repository at __[github](https://github.com/e-sensing/)__\n",
    "- our project at __[research gate](https://www.researchgate.net/project/e-sensing-big-earth-observation-data-analytics-for-land-use-and-land-cover-change-information-wwwesensingorg)__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Time Series Service\n",
    "\n",
    "The Web Time Series Service (WTSS) is a lightweight web service for handling time series data from remote sensing imagery. It exposes three operations:\n",
    "- ```list_coverages```: get the list of available coverages.\n",
    "- ```describe_coverage```: get metadata about a specific coverage.\n",
    "- ```time_series```: get a time series for a given location and time interval.\n",
    "\n",
    "WTSS is developed and maintained by the National Institute for Space Research of Brazil (__[INPE](http://www.inpe.br/)__), where we have a WTSS server instance running. It can be accessed in the address www.dpi.inpe.br/tws .\n",
    "\n",
    "For additional details such as the source code and the WTSS clients for Python, R, Javascript and C++ go to the __[WTSS repository](https://github.com/e-sensing/tws/tree/master/src/tws/wtss)__. \n",
    "\n",
    "If you are interested on setting your own WTSS server, you can contact us through the __[e-sensing](http://esensing.org/)__ links provided above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WTSS for Python\n",
    "\n",
    "The __[python client](https://github.com/e-sensing/wtss.py)__ for WTSS enables users to retrieve time series of Earth observation data for specific locations, using a few lines of code.\n",
    " WTSS easily integrates with Python analysis libraries such as __[numpy](http://www.numpy.org)__, __[scipy](https://www.scipy.org)__, __[pandas](http://pandas.pydata.org)__ and __[matplotlib](https://matplotlib.org)__.\n",
    "\n",
    "### WTSS: List coverages\n",
    "\n",
    "This operation gets a list of the data sets hosted in a WTSS server. In the example below, we import the WTSS module and then create a WTSS object to query and print the list of available data sets in the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# WTSS python client: Access to data & metadata\n",
    "from wtss import wtss\n",
    "\n",
    "# connect to e-Sensing server\n",
    "w = wtss(\"http://www.dpi.inpe.br/tws\")\n",
    "\n",
    "# print the available data sets\n",
    "cv_list = w.list_coverages()\n",
    "for cv_name in cv_list[\"coverages\"]:\n",
    "    print(cv_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WTSS: Describe coverage\n",
    "\n",
    "This operations enables users to explore the details of a data set in the WTSS server. Below, we ask WTSS for the details of a coverage. Then we format and print the WTSS's reponse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore a WTSS data set\n",
    "cv_scheme = w.describe_coverage(\"mod13q1_512\")\n",
    "\n",
    "# format response\n",
    "print(\"ARRAY: {}\".format(cv_scheme[\"name\"]))\n",
    "print(\"\\nDESCRIPTION:\\n\" + str(cv_scheme['description']) + \" - \" + str(cv_scheme['detail']))\n",
    "print(\"\\nDIMENSIONS:{}\\n\".format(cv_scheme['dimensions']))\n",
    "print(\"\\nSPATIAL EXTENT:{}\\n\".format(cv_scheme['spatial_extent']))\n",
    "print(\"\\nCRS:{}\\n\".format(cv_scheme['crs']['wkt']))\n",
    "print(\"\\nTIMELINE:\\nFirst five: {}...\\nLast  five: ...{}\".format(cv_scheme['timeline'][0:5], cv_scheme['timeline'][-5:]))\n",
    "\n",
    "print(\"\\nATTRIBUTES:\")\n",
    "\n",
    "for att in cv_scheme['attributes']:\n",
    "    print(\"{}: {}. Type: {}\".format(att['name'], att['description'], att['datatype']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WTSS: Time series\n",
    "\n",
    "This operation retrieves a time series of the provided point. Here, we ask WTSS for some vegetation indexes, then we create *pandas* series out of them, and finally we put the series together into a *pandas* data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# a location that we are interested in observing land dynamics\n",
    "latitude = -14.919100049\n",
    "longitude = -59.11781088\n",
    "\n",
    "# get time series of a point\n",
    "ts = w.time_series(\"mod13q1_512\", (\"ndvi\", \"evi\"), latitude, longitude)\n",
    "\n",
    "# build a data frame made of vegetation indexes (considering the scale factor)\n",
    "ndvi = pd.Series(ts[\"ndvi\"], index = ts.timeline)/10000\n",
    "evi  = pd.Series(ts[\"evi\"],  index = ts.timeline)/10000\n",
    "\n",
    "vidf = pd.DataFrame({'ndvi': ndvi, 'evi': evi})\n",
    "vidf[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show the choosen location on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsmap import *\n",
    "\n",
    "location = {'lon': longitude, 'lat': latitude}\n",
    "map = createTSMap(location, vidf, 4)\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WTSS and Python Data Analysis Library\n",
    "\n",
    "### Data Visualization\n",
    "\n",
    "Python provides tools for scientific data visualization. Below, we take advantage of the integration between *pandas* and *matplotlib* in order to plot our vegetation indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "from cycler import cycler\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "# Updating default matplotlib colors\n",
    "colors = cycler(u'color', [u'#74c476',u'#6baed6',u'#d62728', u'#ff7f0e', u'#756bb1'])\n",
    "matplotlib.rcParams['axes.prop_cycle'] = colors\n",
    "\n",
    "# Time series visualization\n",
    "fig, ax = matplotlib.pyplot.subplots(figsize = (15, 5))\n",
    "ax.plot()\n",
    "vidf['ndvi'].plot()\n",
    "vidf['evi'].plot()\n",
    "ax.legend()\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Line fitting\n",
    "\n",
    "A simple way to reveal coarse trends in time series is to adjust a straight line through the data. In the code below, we have a function to fit lines which we use in our time series. Then we plot the vegetation indexes along the adjusted lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linearmodel import *\n",
    "\n",
    "# fit a line to the vegetation indexes\n",
    "vidf['ndvi_lm'] = fitline(vidf['ndvi'])\n",
    "vidf['evi_lm'] = fitline(vidf['evi'])\n",
    "\n",
    "# plot\n",
    "fig, ax = matplotlib.pyplot.subplots(figsize = (15, 5))\n",
    "ax.plot()\n",
    "vidf['ndvi'].plot()\n",
    "vidf['evi'].plot()\n",
    "vidf['ndvi_lm'].plot()\n",
    "vidf['evi_lm'].plot()\n",
    "ax.legend()\n",
    "fig.autofmt_xdate()\n",
    "vidf[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fourier decomposition\n",
    "\n",
    "Fourier series analysis allow us to decompose time series into a sum of waves represented by periodic functions. These functions have properties such as amplitude, wavelength, and frequency. In time series analysis, it is accepted that high frequencies are associated with noise. Therefore, in order to diminish noise we need to remove high frequencies from our time series. The use of Fourier series to estimate vegetation phenology was addresed by Atkinson [[Atkinson2012]](#references).\n",
    "\n",
    "In the example below, we use our implementation of the Fourier filter function which takes as parameter a time series and the number of low frequencies to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fourier import *\n",
    "\n",
    "# filter the vi\n",
    "vidf['ndvi_ff'] = fourierfilter(vidf['ndvi'], 25)\n",
    "vidf['evi_ff'] = fourierfilter(vidf['evi'], 45)\n",
    "\n",
    "# plot\n",
    "fig, ax = matplotlib.pyplot.subplots(figsize = (15, 5))\n",
    "ax.plot()\n",
    "vidf['ndvi'].plot()\n",
    "vidf['evi'].plot()\n",
    "vidf['ndvi_ff'].plot()\n",
    "vidf['evi_ff'].plot()\n",
    "ax.legend()\n",
    "fig.autofmt_xdate()\n",
    "vidf[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Whittaker smoothing filter\n",
    "\n",
    "Whitakker filter is obtained by a linear combination of time series nearest neighbors points measures [[Eilers2003]](#references). This filter produces good results for smoothing time-series of satellite data in order to estimate vegetation phenology as reported in  [[Atkinson2012]](#references)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whittaker import *\n",
    "\n",
    "# filter the vi\n",
    "vidf['ndvi_wf'] = pd.Series(whittaker_filter(ndvi), index = ts.timeline)\n",
    "vidf['evi_wf']  = pd.Series(whittaker_filter(evi), index = ts.timeline)\n",
    "\n",
    "# plot\n",
    "fig, ax = matplotlib.pyplot.subplots(figsize = (15, 5))\n",
    "ax.plot()\n",
    "vidf['ndvi'].plot()\n",
    "vidf['evi'].plot()\n",
    "vidf['ndvi_wf'].plot()\n",
    "vidf['evi_wf'].plot()\n",
    "ax.legend()\n",
    "fig.autofmt_xdate()\n",
    "vidf[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kalman filter\n",
    "\n",
    "The Kalman filter aims to separate time series from noise. It is an iterative algorithm on which the outputs of one iteration are the inputs for the next one. In this way, the filter successively improves its estimations of the true value of a time series. \n",
    "\n",
    "In the example below, we estimate the initial parameters for the filter from the time series itself. Then we compute the Kalman filter and plot the smoothed vegetation indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kalman import *\n",
    "\n",
    "# filter the vi\n",
    "vidf['ndvi_kf'] = pd.Series(kalmanfilter(ndvi), index = ts.timeline)\n",
    "vidf['evi_kf']  = pd.Series(kalmanfilter(evi), index = ts.timeline)\n",
    "\n",
    "# plot\n",
    "fig, ax = matplotlib.pyplot.subplots(figsize = (15, 5))\n",
    "ax.plot()\n",
    "vidf['ndvi'].plot()\n",
    "vidf['evi'].plot()\n",
    "vidf['ndvi_kf'].plot()\n",
    "vidf['evi_kf'].plot()\n",
    "ax.legend()\n",
    "fig.autofmt_xdate()\n",
    "vidf[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic Time Warping\n",
    "\n",
    "Dynamic Time Warping (DTW) is pattern matching algorithm. It relies on a shape-based distance function that sequentially warps the time dimension in order to find the best match --- the minimum the distance --- between two time series: The pattern and the sample series. Below we show how to classify time series using DTW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Patterns\n",
    "\n",
    "Our patterns are idealized one-year time-series of the [Forest](Forest) and the [Cerrado](https://en.wikipedia.org/wiki/Cerrado) regions in Brazil.  These patterns were obtained using a [Generalized Additive Model](https://en.wikipedia.org/wiki/Generalized_additive_model) over a large amount of selected time series.\n",
    "\n",
    "Below we show how to read and plot the aforementioned patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtw import *\n",
    "from tools import *\n",
    "\n",
    "# open the pattern file\n",
    "patterns_ts = pd.read_json(\"examples/patterns.json\", orient='records')\n",
    "# update timeline type from str to datetime\n",
    "patterns_ts[\"timeline\"] = pd.to_datetime(patterns_ts[\"timeline\"])\n",
    "plot_time_series(patterns_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Samples\n",
    "\n",
    "We have a file of sample locations which we would like to classify using the patterns listed above. For the sake of this example, we already know that these locations belong to either the Forest or Cerrado region. These ten locations are in the Brazilian state of Mato Grosso and they were verified on the field.\n",
    "\n",
    "Below we read the file with the sample locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read sample file\n",
    "samples = pd.read_csv(\"examples/samples.csv\")\n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we get the time series of MODIS data of these locations. We do this in the background using WTSS python client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wtss_get_time_series is implemented in 'tools.py'\n",
    "samples_ts = wtss_get_time_series(samples)\n",
    "\n",
    "# rescale vegetation index to -1.0~1.0 range\n",
    "samples_ts[\"ndvi\"] *= 0.0001\n",
    "samples_ts[\"evi\"] *= 0.0001\n",
    "\n",
    "samples_ts[0:5]\n",
    "plot_time_series(samples_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classify\n",
    "\n",
    "It is time to classify the sample locations using our patterns. We do this by computing the DTW distance from each pattern to each sample. Then we assign to each sample the name of the pattern with the minimum DTW distance.\n",
    "\n",
    "To achieve this, we use the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify using DTW\n",
    "classification = classifier_1nn(patterns_ts, samples_ts)\n",
    "\n",
    "# print the classification rersults\n",
    "classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification results\n",
    "\n",
    "The results above prove that DTW and our patterns do a good job. We managed to correctly classify 9 out of ten time series. However, the sample location number 3 is incorrectly classified as it is Cerrado but it was assigned to the Forest label.\n",
    "\n",
    "To find what happened, we plot the Forest and Cerrado patterns along the time series of the sample location number three. We can see there how this sample doesn't fit very well to either of the two patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let see what happened with sample #3\n",
    "plot_time_series(pd.concat([samples_ts[samples_ts[\"id\"].isin([3])], patterns_ts]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final remarks\n",
    "\n",
    "We introduced the Web Time Series Service (WTSS), a light weight Web Service of time series of Earth observation data. Through examples and code, we show how the WTSS is used and integrated to Python's scientific libraries such as NumPy, SciPy and Pandas. Therefore, we demonstrated how WTSS fits into the analytic work flow of Earth Observation Scientists.\n",
    "\n",
    "What are the constraints of WTSS? What is missing?\n",
    "- So far, our WTSS implementation only provides data from MODIS __[MOD13Q1](https://lpdaac.usgs.gov/dataset_discovery/modis/modis_products_table/mod13q1)__\n",
    "- The WTSS interface is still simple, we need to extend the service in order to serve complex applications\n",
    "- Regarding Map Algebra, WTSS enables local operations. We need to extend it to focal, zonal and global operations.\n",
    "- WTSS is about time series analysis. But we still need to see cubes of satellite data as images. In other words, we need the equivalent of Web Mapping Server, Web Feature Service, and Web Coverage Server for big Earth observation data.\n",
    "- Our Array database cluster (SciDB) is slow for retrieving images and it does not have native support for the spatio-temporal metadata associated with Earth observation imagery\n",
    "\n",
    "Finally, we would like to invite you to explore some results of the **e-sensing** project by clicking __[here](http://terrabrasilis.info/composer/E-SENSING)__. We are working on new features of WTSS and also a new Web Service for processing large amounts of Earth observation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source code\n",
    "\n",
    "The examples introduced here rely on open source python modules. Our code is available here:\n",
    "- Map\n",
    "  - [tsmap.py](./tsmap.py) Display maps in Jupyter notebooks.\n",
    "- Filter\n",
    "  - [linearmodel.py](./linearmodel.py) Fit linear models to time series.\n",
    "  - [fourier.py](./fourier.py) Filter time series using the Fast Fourier Transformation.\n",
    "  - [kalman.py](./kalman.py) Filter time series using the Kalman filter.\n",
    "  - [whittaker.py](./whittaker.py) Filter time series using the whittaker smoother.\n",
    "- Classification. DTW relies in the following modules: \n",
    "  - [dtw.py](./dtw.py) Implementation of Dynamic Time Warping.\n",
    "  - [tools.py](./tools.py) Utilitary functions for retrieving and plotting time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "<a id=\"references\"></a>\n",
    "\n",
    "[Atkinson2012]: P. M. Atkinson, C. Jeganathan, J. Dash, and C. Atzberger, “Inter-comparison of four models for smoothing satellite sensor time-series data to estimate vegetation phenology,” Remote Sens. Environ., vol. 123, pp. 400–417, Aug. 2012.\n",
    "\n",
    "[Eilers2003]: Paul H. C. Eilers. \"A Perfect Smoother\". Analytical Chemistry, 2003, 75 (14), pp 3631–3636.\n",
    "\n",
    "\n",
    "[Vinhas2016]: L. Vinhas; G. R. Queiroz; K. R. Ferreira; Camara, G. [Web Services for Big Earth Observation Data](http://urlib.net/8JMKD3MGP3W34P/3N2U9JL). In: BRAZILIAN SYMPOSIUM ON GEOINFORMATICS, 17. (GEOINFO), 2016, Campos do Jordão, SP. Proceedings... 2016."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python [geospatial]",
   "language": "python",
   "name": "geospatial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
